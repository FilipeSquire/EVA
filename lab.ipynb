{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe7a6b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 5 seconds...\n",
      "Transcribing...\n",
      "[0.00s -> 3.00s]  Testing the tiny model.\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# 1. Setup Model (Download happens automatically on first run)\n",
    "# Use \"tiny\" for speed, \"base\" for accuracy.\n",
    "# device=\"cuda\" for your GTX 1060, or \"cpu\" for Mac (CTranslate2 has specific Mac support too)\n",
    "model_size = \"tiny\" \n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "print(\"Recording for 5 seconds...\")\n",
    "\n",
    "# 2. Record Audio\n",
    "fs = 16000  # Whisper expects 16kHz audio\n",
    "duration = 5  # seconds\n",
    "recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')\n",
    "sd.wait()  # Wait until recording is finished\n",
    "\n",
    "print(\"Transcribing...\")\n",
    "\n",
    "# 3. Transcribe\n",
    "# Whisper expects raw audio data\n",
    "segments, info = model.transcribe(recording.flatten(), beam_size=5)\n",
    "\n",
    "for segment in segments:\n",
    "    print(f\"[{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb1dde13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/homebrew/lib/python3.11/site-packages/openwakeword/resources/models/alexa_v0.1.tflite', '/opt/homebrew/lib/python3.11/site-packages/openwakeword/resources/models/hey_mycroft_v0.1.tflite', '/opt/homebrew/lib/python3.11/site-packages/openwakeword/resources/models/hey_jarvis_v0.1.tflite', '/opt/homebrew/lib/python3.11/site-packages/openwakeword/resources/models/hey_rhasspy_v0.1.tflite', '/opt/homebrew/lib/python3.11/site-packages/openwakeword/resources/models/timer_v0.1.tflite', '/opt/homebrew/lib/python3.11/site-packages/openwakeword/resources/models/weather_v0.1.tflite']\n"
     ]
    }
   ],
   "source": [
    "import openwakeword\n",
    "print(openwakeword.get_pretrained_model_paths())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9951aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Wake Word Model...\n",
      "Loading Silero VAD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/felipesilverio/.cache/torch/hub/snakers4_silero-vad_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SYSTEM READY ---\n",
      "Say 'Hey Jarvis' to trigger me.\n",
      "\n",
      "ðŸ¤– WAKE WORD DETECTED! (Listening for command...)\n",
      "âœ… End of speech detected. Processing...\n",
      "Transcribed:  That's it, I think I can correctly detect what I'm saying.\n",
      "Returning to sleep...\n",
      "\n",
      "ðŸ¤– WAKE WORD DETECTED! (Listening for command...)\n",
      "âœ… End of speech detected. Processing...\n",
      "Transcribed:  A job is\n",
      "Returning to sleep...\n",
      "\n",
      "ðŸ¤– WAKE WORD DETECTED! (Listening for command...)\n",
      "âœ… End of speech detected. Processing...\n",
      "Transcribed:  I want to test.\n",
      "Returning to sleep...\n",
      "\n",
      "ðŸ¤– WAKE WORD DETECTED! (Listening for command...)\n",
      "âœ… End of speech detected. Processing...\n",
      "Transcribed:  Proceed.\n",
      "Returning to sleep...\n",
      "\n",
      "ðŸ¤– WAKE WORD DETECTED! (Listening for command...)\n",
      "âœ… End of speech detected. Processing...\n",
      "Transcribed:  Hey, Jarvis.\n",
      "Returning to sleep...\n",
      "\n",
      "ðŸ¤– WAKE WORD DETECTED! (Listening for command...)\n",
      "âœ… End of speech detected. Processing...\n",
      "Transcribed:  I want to test the accuracy.\n",
      "Returning to sleep...\n",
      "\n",
      "ðŸ¤– WAKE WORD DETECTED! (Listening for command...)\n",
      "\n",
      "Stopping...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import openwakeword\n",
    "from openwakeword.model import Model\n",
    "import torch\n",
    "import collections\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Both models work best at 16000 Hz\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "# OpenWakeWord prefers chunks of 1280 samples (80ms) for efficiency, but works with smaller multiples\n",
    "CHUNK = 512 \n",
    "WAKE_WORD_THRESHOLD = 0.5\n",
    "\n",
    "# Initialize Whisper model\n",
    "whisper_model = WhisperModel(\"tiny\", device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "# --- INITIALIZE MODELS ---\n",
    "print(\"Loading Wake Word Model...\")\n",
    "# Using the pre-trained 'hey_jarvis' model. You can swap this later.\n",
    "oww_model = Model(wakeword_models=[\"hey_jarvis\"], inference_framework=\"onnx\")\n",
    "\n",
    "print(\"Loading Silero VAD...\")\n",
    "# Load Silero VAD from Torch Hub (downloads automatically)\n",
    "vad_model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                                  model='silero_vad',\n",
    "                                  force_reload=False)\n",
    "(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
    "vad_iterator = VADIterator(vad_model)\n",
    "\n",
    "# --- AUDIO STREAM SETUP ---\n",
    "audio = pyaudio.PyAudio()\n",
    "stream = audio.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"\\n--- SYSTEM READY ---\")\n",
    "print(\"Say 'Hey Jarvis' to trigger me.\")\n",
    "\n",
    "# --- STATE MANAGEMENT ---\n",
    "# Buffer to store audio when user is speaking\n",
    "audio_buffer = collections.deque() \n",
    "is_awake = False \n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # 1. Get Audio Chunk\n",
    "        data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "        # Convert raw bytes to numpy array (int16)\n",
    "        audio_int16 = np.frombuffer(data, dtype=np.int16)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # STATE 1: PASSIVE LISTENING (Waiting for Wake Word)\n",
    "        # ---------------------------------------------------------\n",
    "        if not is_awake:\n",
    "            # Feed audio to OpenWakeWord\n",
    "            prediction = oww_model.predict(audio_int16)\n",
    "            \n",
    "            # Check if \"hey_jarvis\" score is high enough\n",
    "            if prediction[\"hey_jarvis\"] > WAKE_WORD_THRESHOLD:\n",
    "                print(\"\\nðŸ¤– WAKE WORD DETECTED! (Listening for command...)\")\n",
    "                is_awake = True\n",
    "                vad_iterator.reset_states() # Reset VAD logic\n",
    "                audio_buffer.clear() # Clear old audio\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # STATE 2: ACTIVE LISTENING (VAD / Recording)\n",
    "        # ---------------------------------------------------------\n",
    "        else:\n",
    "            # Silero expects float32 tensor between -1 and 1\n",
    "            audio_float32 = torch.from_numpy(audio_int16.astype(np.float32) / 32768.0)\n",
    "            \n",
    "            # Feed to VAD Iterator\n",
    "            # This function returns a dict if speech starts or ends\n",
    "            speech_dict = vad_iterator(audio_float32, return_seconds=True)\n",
    "            \n",
    "            # Always save audio while awake (so we don't miss words)\n",
    "            audio_buffer.append(data)\n",
    "\n",
    "            # Check if Silero thinks you stopped talking\n",
    "            if speech_dict:\n",
    "                if \"end\" in speech_dict:\n",
    "                    print(\"âœ… End of speech detected. Processing...\")\n",
    "                    \n",
    "                    # Transcribe the captured audio using Whisper\n",
    "                    full_audio_data = b''.join(audio_buffer)\n",
    "                    audio_int16 = np.frombuffer(full_audio_data, dtype=np.int16)\n",
    "                    audio_float32 = audio_int16.astype(np.float32) / 32768.0\n",
    "                    segments, info = whisper_model.transcribe(audio_float32.flatten(), beam_size=5)\n",
    "                    transcription = \" \".join([segment.text for segment in segments])\n",
    "                    print(f\"Transcribed: {transcription}\")\n",
    "                    print(\"Returning to sleep...\")\n",
    "                    \n",
    "                    is_awake = False\n",
    "                    audio_buffer.clear()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopping...\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e177e478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement tflite-runtime (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for tflite-runtime\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tflite-runtime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
